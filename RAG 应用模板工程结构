# RAG åº”ç”¨æ¨¡æ¿å·¥ç¨‹ç»“æ„

# é¡¹ç›®ç»“æ„ç›®å½•

rag_app/
â”œâ”€â”€ app.py                    # âœ… é¡¹ç›®ä¸»å…¥å£ï¼ˆStreamlit Web UIï¼‰
â”œâ”€â”€ requirements.txt          # ä¾èµ–æ–‡ä»¶
â”œâ”€â”€ .env                      # å­˜æ”¾ OPENAI_API_KEY ç­‰å¯†é’¥ï¼ˆå¯é€‰ï¼‰
â”‚
â”œâ”€â”€ loaders/                  # ğŸ“‚ æ–‡æ¡£åŠ è½½å™¨æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf_loader.py         # åŠ è½½ PDFï¼ˆPyMuPDFParserï¼‰
â”‚   â””â”€â”€ csv_loader.py         # åŠ è½½ CSVï¼ˆè‡ªå®šä¹‰ï¼‰
â”‚
â”œâ”€â”€ parsers/                  # ğŸ“‚ Blob è§£æå™¨æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ csv_parser.py         # CSV æ–‡ä»¶è½¬ Documentï¼ˆç»§æ‰¿ BaseBlobParserï¼‰
â”‚
â”œâ”€â”€ retrievers/               # ğŸ“‚ è‡ªå®šä¹‰æ£€ç´¢å™¨æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ keyword_retriever.py  # å…³é”®è¯åŒ¹é…æ£€ç´¢å™¨ï¼ˆéå‘é‡ï¼‰
â”‚
â”œâ”€â”€ chains/                   # ğŸ“‚ RAG Chain æ„å»ºé€»è¾‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ rag_chain.py          # æ„å»º RetrievalQA + è®°å¿†åŠŸèƒ½
â”‚
â”œâ”€â”€ memory/                   # ğŸ“‚ å¯¹è¯å†å²æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ memory_router.py      # session_id -> message history
â”‚   â””â”€â”€ redis_memory.py       # æŒä¹…åŒ–å†å²ï¼ˆRedis å¯é€‰ï¼‰
â”‚
â””â”€â”€ utils/                    # ğŸ“‚ å·¥å…·å‡½æ•°æ¨¡å—
    â”œâ”€â”€ __init__.py
    â””â”€â”€ file_utils.py         # å¤„ç†ä¸Šä¼ æ–‡ä»¶ã€è½¬ Blob ç­‰è¾…åŠ©é€»è¾‘


# ç¤ºä¾‹ï¼šloaders/pdf_loader.py
from langchain_community.document_loaders.blob_loaders import Blob
from langchain_community.document_loaders.parsers.pdf import PyMuPDFParser

def load_pdf(file_bytes: bytes, filename: str):
    blob = Blob.from_data(file_bytes, path=filename)
    parser = PyMuPDFParser()
    return parser.parse(blob)  # è¿”å› List[Document]


# ç¤ºä¾‹ï¼šchains/rag_chain.py
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

def build_rag_chain(retriever):
    llm = ChatOpenAI(model="gpt-4o")
    chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)
    return chain


# ç¤ºä¾‹ï¼šapp.pyï¼ˆä¸»å…¥å£ï¼‰
import streamlit as st 
from loaders.pdf_loader import load_pdf
from chains.rag_chain import build_rag_chain
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

st.title("ğŸ“„ RAG æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")
uploaded_file = st.file_uploader("ä¸Šä¼  PDF æ–‡æ¡£", type=["pdf"])

if uploaded_file:
    docs = load_pdf(uploaded_file.read(), uploaded_file.name)
    # å¯æ¥å…¥åˆ†å—ã€embeddingã€å‘é‡åº“
    splitter = ...
    embedding = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectorstore = FAISS.from_documents(docs, embedding)
    retriever = vectorstore.as_retriever()

    rag_chain = build_rag_chain(retriever)

    query = st.text_input("è¯·è¾“å…¥é—®é¢˜ï¼š")
    if query:
        response = rag_chain.invoke({"query": query})
        st.write(response["result"])
        for doc in response["source_documents"]:
            st.code(doc.page_content[:200] + "...")
